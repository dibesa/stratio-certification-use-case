{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Deployment using PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we are going to deploy as microservice the model built in the previous [notebook](./model.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries and data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mleap import pyspark\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from mleap.pyspark.spark_support import SimpleSparkSerializer\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.ml.feature import VectorAssembler, MaxAbsScaler, OneHotEncoder, StringIndexer\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.classification import NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file_path = \"/sparta/dibesa/german_credit_data_labels.csv\"\n",
    "df = spark.read.csv(file_path, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove unusable columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---------------+----------------+-------------+--------+-------------------+----+\n",
      "|Age|Housing|Saving accounts|Checking account|Credit amount|Duration|            Purpose|Risk|\n",
      "+---+-------+---------------+----------------+-------------+--------+-------------------+----+\n",
      "| 67|    own|             NA|          little|         1169|       6|           radio/TV|good|\n",
      "| 22|    own|         little|        moderate|         5951|      48|           radio/TV| bad|\n",
      "| 49|    own|         little|              NA|         2096|      12|          education|good|\n",
      "| 45|   free|         little|          little|         7882|      42|furniture/equipment|good|\n",
      "| 53|   free|         little|          little|         4870|      24|                car| bad|\n",
      "| 35|   free|             NA|              NA|         9055|      36|          education|good|\n",
      "| 53|    own|     quite rich|              NA|         2835|      24|furniture/equipment|good|\n",
      "| 35|   rent|         little|        moderate|         6948|      36|                car|good|\n",
      "| 61|    own|           rich|              NA|         3059|      12|           radio/TV|good|\n",
      "| 28|    own|         little|        moderate|         5234|      30|                car| bad|\n",
      "| 25|   rent|         little|        moderate|         1295|      12|                car| bad|\n",
      "| 24|   rent|         little|          little|         4308|      48|           business| bad|\n",
      "| 22|    own|         little|        moderate|         1567|      12|           radio/TV|good|\n",
      "| 60|    own|         little|          little|         1199|      24|                car| bad|\n",
      "| 28|   rent|         little|          little|         1403|      15|                car|good|\n",
      "| 32|    own|       moderate|          little|         1282|      24|           radio/TV| bad|\n",
      "| 53|    own|             NA|              NA|         2424|      24|           radio/TV|good|\n",
      "| 25|    own|             NA|          little|         8072|      30|           business|good|\n",
      "| 44|   free|         little|        moderate|        12579|      24|                car| bad|\n",
      "| 31|    own|     quite rich|              NA|         3430|      24|           radio/TV|good|\n",
      "+---+-------+---------------+----------------+-------------+--------+-------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.drop('Sex', 'Job', 'ID')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---------------+----------------+-------------+--------+-------------------+-----------+\n",
      "|Age|Housing|Saving accounts|Checking account|Credit amount|Duration|            Purpose|Binary_Risk|\n",
      "+---+-------+---------------+----------------+-------------+--------+-------------------+-----------+\n",
      "| 67|    own|             NA|          little|         1169|       6|           radio/TV|        0.0|\n",
      "| 22|    own|         little|        moderate|         5951|      48|           radio/TV|        1.0|\n",
      "| 49|    own|         little|              NA|         2096|      12|          education|        0.0|\n",
      "| 45|   free|         little|          little|         7882|      42|furniture/equipment|        0.0|\n",
      "| 53|   free|         little|          little|         4870|      24|                car|        1.0|\n",
      "| 35|   free|             NA|              NA|         9055|      36|          education|        0.0|\n",
      "| 53|    own|     quite rich|              NA|         2835|      24|furniture/equipment|        0.0|\n",
      "| 35|   rent|         little|        moderate|         6948|      36|                car|        0.0|\n",
      "| 61|    own|           rich|              NA|         3059|      12|           radio/TV|        0.0|\n",
      "| 28|    own|         little|        moderate|         5234|      30|                car|        1.0|\n",
      "| 25|   rent|         little|        moderate|         1295|      12|                car|        1.0|\n",
      "| 24|   rent|         little|          little|         4308|      48|           business|        1.0|\n",
      "| 22|    own|         little|        moderate|         1567|      12|           radio/TV|        0.0|\n",
      "| 60|    own|         little|          little|         1199|      24|                car|        1.0|\n",
      "| 28|   rent|         little|          little|         1403|      15|                car|        0.0|\n",
      "| 32|    own|       moderate|          little|         1282|      24|           radio/TV|        1.0|\n",
      "| 53|    own|             NA|              NA|         2424|      24|           radio/TV|        0.0|\n",
      "| 25|    own|             NA|          little|         8072|      30|           business|        0.0|\n",
      "| 44|   free|         little|        moderate|        12579|      24|                car|        1.0|\n",
      "| 31|    own|     quite rich|              NA|         3430|      24|           radio/TV|        0.0|\n",
      "+---+-------+---------------+----------------+-------------+--------+-------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder = StringIndexer(inputCol='Risk', outputCol='Binary_Risk')\n",
    "df = encoder.fit(df).transform(df)\n",
    "df = df.drop('Risk')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform data for our use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+-------------+-----------------+--------------+------------+----------------+-----------+----------+--------------+---------+\n",
      "|Binary_Risk|Checking_little|Checking_null|Checking_moderate|Savings_little|Savings_null|Purpose_radio/TV|Housing_own|Credit_big|Duration_short|Age_young|\n",
      "+-----------+---------------+-------------+-----------------+--------------+------------+----------------+-----------+----------+--------------+---------+\n",
      "|        0.0|              1|          0.0|                0|             0|           0|               1|          1|         0|             1|        0|\n",
      "|        1.0|              0|          0.0|                1|             1|           1|               1|          1|         0|             0|        1|\n",
      "|        0.0|              0|          1.0|                0|             1|           1|               0|          1|         0|             0|        0|\n",
      "|        0.0|              1|          0.0|                0|             1|           1|               0|          0|         0|             0|        0|\n",
      "|        1.0|              1|          0.0|                0|             1|           1|               0|          0|         0|             0|        0|\n",
      "|        0.0|              0|          1.0|                0|             0|           0|               0|          0|         0|             0|        0|\n",
      "|        0.0|              0|          1.0|                0|             0|           0|               0|          1|         0|             0|        0|\n",
      "|        0.0|              0|          0.0|                1|             1|           1|               0|          0|         0|             0|        0|\n",
      "|        0.0|              0|          1.0|                0|             0|           0|               1|          1|         0|             0|        0|\n",
      "|        1.0|              0|          0.0|                1|             1|           1|               0|          1|         0|             0|        0|\n",
      "|        1.0|              0|          0.0|                1|             1|           1|               0|          0|         0|             0|        1|\n",
      "|        1.0|              1|          0.0|                0|             1|           1|               0|          0|         0|             0|        1|\n",
      "|        0.0|              0|          0.0|                1|             1|           1|               1|          1|         0|             0|        1|\n",
      "|        1.0|              1|          0.0|                0|             1|           1|               0|          1|         0|             0|        0|\n",
      "|        0.0|              1|          0.0|                0|             1|           1|               0|          0|         0|             0|        0|\n",
      "|        1.0|              1|          0.0|                0|             0|           0|               1|          1|         0|             0|        0|\n",
      "|        0.0|              0|          1.0|                0|             0|           0|               1|          1|         0|             0|        0|\n",
      "|        0.0|              1|          0.0|                0|             0|           0|               0|          1|         0|             0|        1|\n",
      "|        1.0|              0|          0.0|                1|             1|           1|               0|          0|         1|             0|        0|\n",
      "|        0.0|              0|          1.0|                0|             0|           0|               1|          1|         0|             0|        0|\n",
      "+-----------+---------------+-------------+-----------------+--------------+------------+----------------+-----------+----------+--------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('Checking_little', f.when(f.col('Checking account') == \"little\", 1).otherwise(0))\n",
    "df = df.withColumn('Checking_null', f.when(f.col('Checking account') == \"NA\", 1.0).otherwise(0))\n",
    "df = df.withColumn('Checking_moderate', f.when(f.col('Checking account') == \"moderate\", 1).otherwise(0))\n",
    "df = df.withColumn('Savings_little', f.when(f.col('Saving accounts') == \"little\", 1).otherwise(0))\n",
    "df = df.withColumn('Savings_null', f.when(f.col('Saving accounts') == \"little\", 1).otherwise(0))\n",
    "df = df.withColumn('Purpose_radio/TV', f.when(f.col('Purpose') == \"radio/TV\", 1).otherwise(0))\n",
    "df = df.withColumn('Housing_own', f.when(f.col('Housing') == \"own\", 1).otherwise(0))\n",
    "df = df.withColumn('Credit_big', f.when(f.col('Credit amount') > 10000, 1).otherwise(0))\n",
    "df = df.withColumn('Duration_short', f.when(f.col('Duration') < 12, 1).otherwise(0))\n",
    "df = df.withColumn('Age_young', f.when(f.col('Age') < 27, 1).otherwise(0))\n",
    "\n",
    "df = df.drop('Age', 'Housing', 'Saving accounts', 'Checking account', 'Credit amount', 'Duration', 'Purpose')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Checking_little',\n",
       " 'Checking_null',\n",
       " 'Checking_moderate',\n",
       " 'Savings_little',\n",
       " 'Savings_null',\n",
       " 'Purpose_radio/TV',\n",
       " 'Housing_own',\n",
       " 'Credit_big',\n",
       " 'Duration_short',\n",
       " 'Age_young']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = df.columns\n",
    "features = features[1:]\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_feature_assembler = VectorAssembler(inputCols=features, outputCol=\"all_features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble our features and feature pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished constructing the pipeline\n"
     ]
    }
   ],
   "source": [
    "featurePipeline = Pipeline(stages=[continuous_feature_assembler])\n",
    "\n",
    "sparkFeaturePipelineModel = featurePipeline.fit(df)\n",
    "\n",
    "print(\"Finished constructing the pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(ID,IntegerType,true),StructField(Age,IntegerType,true),StructField(Sex,StringType,true),StructField(Job,IntegerType,true),StructField(Housing,StringType,true),StructField(Saving accounts,StringType,true),StructField(Checking account,StringType,true),StructField(Credit amount,IntegerType,true),StructField(Duration,IntegerType,true),StructField(Purpose,StringType,true),StructField(Risk,StringType,true)))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete: Training Naive Bayes\n"
     ]
    }
   ],
   "source": [
    "# Step 3.2 Create our model\n",
    "\n",
    "nb = NaiveBayes(featuresCol=\"all_features\", labelCol=\"Binary_Risk\", smoothing=0.0001, modelType=\"multinomial\")\n",
    "\n",
    "pipeline_nb = [sparkFeaturePipelineModel] + [nb]\n",
    "\n",
    "sparkPipelineEstimatornb = Pipeline(stages = pipeline_nb)\n",
    "\n",
    "sparkPipelinenb = sparkPipelineEstimatornb.fit(df)\n",
    "\n",
    "print(\"Complete: Training Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"marathonState\": {\n",
      "      \"deployments\": [],\n",
      "      \"tasksStaged\": 0,\n",
      "      \"appStatus\": \"not_deployed\",\n",
      "      \"tasksRunning\": 0,\n",
      "      \"tasksUnhealthy\": 0,\n",
      "      \"tasksStatus\": [],\n",
      "      \"tasksHealthy\": 0\n",
      "    },\n",
      "    \"modelName\": \"testboth\",\n",
      "    \"versions\": [\n",
      "      {\n",
      "        \"files\": [\n",
      "          {\n",
      "            \"serializationLibVersion\": \"2.2.0.5\",\n",
      "            \"serializationLib\": \"spark\",\n",
      "            \"modelPath\": \"/intellmodelrep1/models/testboth/v0/testboth-spark-v0.zip\",\n",
      "            \"type\": \"pipelinemodel\"\n",
      "          },\n",
      "          {\n",
      "            \"serializationLibVersion\": \"0.7.0\",\n",
      "            \"serializationLib\": \"mleap\",\n",
      "            \"modelPath\": \"/intellmodelrep1/models/testboth/v0/testboth-mleap-v0.zip\",\n",
      "            \"type\": \"pipelinemodel\"\n",
      "          }\n",
      "        ],\n",
      "        \"user\": \"formacion1\",\n",
      "        \"id\": \"2b77709f-f5e7-4b54-9584-5244e6dadae2\",\n",
      "        \"additionalInfo\": null,\n",
      "        \"modelDescription\": \"This is a sample model\",\n",
      "        \"modelVersion\": 1,\n",
      "        \"timestamp\": \"2019-01-22 11:38:11.371\",\n",
      "        \"kernel\": \"Python3 PySpark 2.2.0\",\n",
      "        \"framework\": \"spark\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"marathonState\": {\n",
      "      \"deployments\": [],\n",
      "      \"tasksStaged\": 0,\n",
      "      \"appStatus\": \"not_deployed\",\n",
      "      \"tasksRunning\": 0,\n",
      "      \"tasksUnhealthy\": 0,\n",
      "      \"tasksStatus\": [],\n",
      "      \"tasksHealthy\": 0\n",
      "    },\n",
      "    \"modelName\": \"testmleap\",\n",
      "    \"versions\": [\n",
      "      {\n",
      "        \"files\": [\n",
      "          {\n",
      "            \"serializationLibVersion\": \"0.7.0\",\n",
      "            \"serializationLib\": \"mleap\",\n",
      "            \"modelPath\": \"/intellmodelrep1/models/testmleap/v0/testmleap-mleap-v0.zip\",\n",
      "            \"type\": \"pipelinemodel\"\n",
      "          }\n",
      "        ],\n",
      "        \"user\": \"formacion1\",\n",
      "        \"id\": \"1e7f36df-cb4c-438d-b6fb-87e8cc8761d0\",\n",
      "        \"additionalInfo\": null,\n",
      "        \"modelDescription\": \"Updated\",\n",
      "        \"modelVersion\": 1,\n",
      "        \"timestamp\": \"2019-01-22 11:39:33.945\",\n",
      "        \"kernel\": \"Python3 PySpark 2.2.0\",\n",
      "        \"framework\": \"spark\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"marathonState\": {\n",
      "      \"deployments\": [],\n",
      "      \"tasksStaged\": 0,\n",
      "      \"appStatus\": \"not_deployed\",\n",
      "      \"tasksRunning\": 0,\n",
      "      \"tasksUnhealthy\": 0,\n",
      "      \"tasksStatus\": [],\n",
      "      \"tasksHealthy\": 0\n",
      "    },\n",
      "    \"modelName\": \"testspark\",\n",
      "    \"versions\": [\n",
      "      {\n",
      "        \"files\": [\n",
      "          {\n",
      "            \"serializationLibVersion\": \"2.2.0.5\",\n",
      "            \"serializationLib\": \"spark\",\n",
      "            \"modelPath\": \"/intellmodelrep1/models/testspark/v0/testspark-spark-v0.zip\",\n",
      "            \"type\": \"pipelinemodel\"\n",
      "          }\n",
      "        ],\n",
      "        \"user\": \"formacion1\",\n",
      "        \"id\": \"2d05f5b4-c6bf-4786-8d24-195299f3cbc8\",\n",
      "        \"additionalInfo\": null,\n",
      "        \"modelDescription\": \"\",\n",
      "        \"modelVersion\": 1,\n",
      "        \"timestamp\": \"2019-01-22 11:39:39.266\",\n",
      "        \"kernel\": \"Python3 PySpark 2.2.0\",\n",
      "        \"framework\": \"spark\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"marathonState\": {\n",
      "      \"deployments\": [],\n",
      "      \"tasksStaged\": 0,\n",
      "      \"appStatus\": \"not_deployed\",\n",
      "      \"tasksRunning\": 0,\n",
      "      \"tasksUnhealthy\": 0,\n",
      "      \"tasksStatus\": [],\n",
      "      \"tasksHealthy\": 0\n",
      "    },\n",
      "    \"modelName\": \"logisticregression\",\n",
      "    \"versions\": [\n",
      "      {\n",
      "        \"files\": [\n",
      "          {\n",
      "            \"serializationLibVersion\": \"2.2.0.5\",\n",
      "            \"serializationLib\": \"spark\",\n",
      "            \"modelPath\": \"/intellmodelrep1/models/logisticregression/v0/logisticregression-spark-v0.zip\",\n",
      "            \"type\": \"pipelinemodel\"\n",
      "          },\n",
      "          {\n",
      "            \"serializationLibVersion\": \"0.7.0\",\n",
      "            \"serializationLib\": \"mleap\",\n",
      "            \"modelPath\": \"/intellmodelrep1/models/logisticregression/v0/logisticregression-mleap-v0.zip\",\n",
      "            \"type\": \"pipelinemodel\"\n",
      "          }\n",
      "        ],\n",
      "        \"user\": \"formacion1\",\n",
      "        \"id\": \"734d1005-3084-47ad-aaaf-42dcf44fc7b7\",\n",
      "        \"additionalInfo\": null,\n",
      "        \"modelDescription\": \"Logistic regression model trained with the data provided by AirBnb\",\n",
      "        \"modelVersion\": 1,\n",
      "        \"timestamp\": \"2019-02-07 17:09:41.592\",\n",
      "        \"kernel\": \"Python3 PySpark 2.2.0\",\n",
      "        \"framework\": \"spark\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"marathonState\": {\n",
      "      \"deployments\": [],\n",
      "      \"tasksStaged\": 0,\n",
      "      \"appStatus\": \"deployed\",\n",
      "      \"tasksRunning\": 1,\n",
      "      \"tasksUnhealthy\": 0,\n",
      "      \"tasksStatus\": [\n",
      "        \"TASK_RUNNING\"\n",
      "      ],\n",
      "      \"tasksHealthy\": 1\n",
      "    },\n",
      "    \"modelName\": \"airbnb\",\n",
      "    \"versions\": [\n",
      "      {\n",
      "        \"files\": [\n",
      "          {\n",
      "            \"serializationLibVersion\": \"2.2.0.5\",\n",
      "            \"serializationLib\": \"spark\",\n",
      "            \"modelPath\": \"/intellmodelrep1/models/airbnb/v0/airbnb-spark-v0.zip\",\n",
      "            \"type\": \"pipelinemodel\"\n",
      "          },\n",
      "          {\n",
      "            \"serializationLibVersion\": \"0.7.0\",\n",
      "            \"serializationLib\": \"mleap\",\n",
      "            \"modelPath\": \"/intellmodelrep1/models/airbnb/v0/airbnb-mleap-v0.zip\",\n",
      "            \"type\": \"pipelinemodel\"\n",
      "          }\n",
      "        ],\n",
      "        \"user\": \"formacion1\",\n",
      "        \"id\": \"7d8b6fc5-edbf-4115-a715-84cf123cc518\",\n",
      "        \"additionalInfo\": null,\n",
      "        \"modelDescription\": \"Linear regression model trained with the data provided by AirBnb\",\n",
      "        \"modelVersion\": 1,\n",
      "        \"timestamp\": \"2019-02-08 08:52:06.191\",\n",
      "        \"kernel\": \"Python3 PySpark 2.2.0\",\n",
      "        \"framework\": \"spark\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "%listPipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Models in HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: savePipeline [-h] [--pipelineName PIPELINENAME]\n",
      "                    [--pipelineModelObject PIPELINEMODELOBJECT]\n",
      "                    [--dataframe DATAFRAME] [--description DESCRIPTION]\n",
      "                    [--additionalInfo ADDITIONALINFO]\n",
      "                    [--serializationLib {mleap,spark}]\n",
      "\n",
      "Serializes a PipelineModel to a zip file and upload it to the configured model\n",
      "repository.\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --pipelineName PIPELINENAME\n",
      "  --pipelineModelObject PIPELINEMODELOBJECT\n",
      "  --dataframe DATAFRAME\n",
      "  --description DESCRIPTION\n",
      "  --additionalInfo ADDITIONALINFO\n",
      "  --serializationLib {mleap,spark}\n"
     ]
    }
   ],
   "source": [
    "%savePipeline -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: deletePipeline [-h] [--pipelineName PIPELINENAME]\n",
      "\n",
      "Deletes a PipelineModel stored in a model repository.\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --pipelineName PIPELINENAME\n"
     ]
    }
   ],
   "source": [
    "%deletePipeline -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: deployPipeline [-h] [--pipelineName PIPELINENAME] [--cpus CPUS]\n",
      "                      [--mem MEM] [--instances INSTANCES]\n",
      "\n",
      "Deploy a PipelineModel stored in a model repository.\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --pipelineName PIPELINENAME\n",
      "  --cpus CPUS           Number of cpus per deployed model microservice.\n",
      "  --mem MEM             Memory per deployed model microservice instance (in\n",
      "                        Megabytes).\n",
      "  --instances INSTANCES\n",
      "                        Number of instances that will be deployed.\n"
     ]
    }
   ],
   "source": [
    "%deployPipeline -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"message\":\"Model 'airbnb' correctly uploaded.\"}\n"
     ]
    }
   ],
   "source": [
    "%savePipeline   --pipelineName dibesa-credit \\\n",
    "                --pipelineModelObject sparkPipelinenb \\\n",
    "                --dataframe dataset_imputed \\\n",
    "                --description \"Linear regression model trained with the data provided by AirBnb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while deleting 'airbnb' model from repository. Response from server:\n",
      " {\"error\":\"ModelMetadataNotExistsException\",\"reason\":\"Model 'airbnb' not found in the metadata repository. \"}\n"
     ]
    }
   ],
   "source": [
    "%deletePipeline --pipelineName dibesa-credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 'airbnb' correctly deployed from repository.\n"
     ]
    }
   ],
   "source": [
    "%deployPipeline --pipelineName dibesa-credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_imputed.write.mode(\"overwrite\").parquet(\"/tmp/airbnb_input.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import decimal\n",
    "\n",
    "def get_mleap_request_body(df, num_entries=10):\n",
    "    schema = df.schema.fields\n",
    "    fields = [{k:v if 'decimal' not in v else 'double' for k,v in x.jsonValue().items() if k in ('name', 'type')} for x in schema]\n",
    "    \n",
    "    field_names = [field['name'] for field in fields]\n",
    "    data = df.limit(num_entries).collect()\n",
    "    rows = [\n",
    "        [row[key] if not isinstance(row[key], decimal.Decimal) else float(row[key]) for key in field_names]\n",
    "        for row in data\n",
    "    ]\n",
    "    body = {'schema': {'fields': fields}, 'rows': rows}\n",
    "    return body\n",
    "\n",
    "def request_to_ms(model_name, df):\n",
    "    url = 'https://microservice-mleap-{0}.microservice.intelligence.marathon.mesos:8080/{0}/transform'.format(model_name)\n",
    "    request_body = get_mleap_request_body(df, num_entries=1)\n",
    "    response = requests.post(url, json=request_body, verify=False)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = get_mleap_request_body(df, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rows': [['1949687',\n",
       "   ' London',\n",
       "   'Other',\n",
       "   'A unique Victorian development of special architectural and historic interest as it combines housing and workshops. This is a thriving artist community, friendly and close to the centre of the city.',\n",
       "   80.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   'Entire home/apt',\n",
       "   0.0,\n",
       "   'moderate',\n",
       "   100.0,\n",
       "   80.0,\n",
       "   8.0,\n",
       "   10.0,\n",
       "   0.0,\n",
       "   20.0,\n",
       "   94.0,\n",
       "   380.0,\n",
       "   0.0]],\n",
       " 'schema': {'fields': [{'name': 'id', 'type': 'string'},\n",
       "   {'name': 'city', 'type': 'string'},\n",
       "   {'name': 'state', 'type': 'string'},\n",
       "   {'name': 'space', 'type': 'string'},\n",
       "   {'name': 'price', 'type': 'double'},\n",
       "   {'name': 'bathrooms', 'type': 'double'},\n",
       "   {'name': 'bedrooms', 'type': 'double'},\n",
       "   {'name': 'room_type', 'type': 'string'},\n",
       "   {'name': 'host_is_superhost', 'type': 'double'},\n",
       "   {'name': 'cancellation_policy', 'type': 'string'},\n",
       "   {'name': 'security_deposit', 'type': 'double'},\n",
       "   {'name': 'price_per_bedroom', 'type': 'double'},\n",
       "   {'name': 'number_of_reviews', 'type': 'double'},\n",
       "   {'name': 'extra_people', 'type': 'double'},\n",
       "   {'name': 'instant_bookable', 'type': 'double'},\n",
       "   {'name': 'cleaning_fee', 'type': 'double'},\n",
       "   {'name': 'review_scores_rating', 'type': 'double'},\n",
       "   {'name': 'square_feet', 'type': 'double'},\n",
       "   {'name': 'n_bathrooms_more_than_two', 'type': 'double'}]}}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/urllib3/connectionpool.py:857: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    }
   ],
   "source": [
    "rr = request_to_ms('examplemodel',df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rows': [['1949687',\n",
       "   ' London',\n",
       "   'Other',\n",
       "   'A unique Victorian development of special architectural and historic interest as it combines housing and workshops. This is a thriving artist community, friendly and close to the centre of the city.',\n",
       "   80.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   'Entire home/apt',\n",
       "   0.0,\n",
       "   'moderate',\n",
       "   100.0,\n",
       "   80.0,\n",
       "   8.0,\n",
       "   10.0,\n",
       "   0.0,\n",
       "   20.0,\n",
       "   94.0,\n",
       "   380.0,\n",
       "   0.0,\n",
       "   {'dimensions': [8],\n",
       "    'values': [1.0, 1.0, 100.0, 20.0, 10.0, 8.0, 380.0, 94.0]},\n",
       "   {'dimensions': [8],\n",
       "    'values': [2.0701404784672404,\n",
       "     1.18111353148471,\n",
       "     0.4089700538272752,\n",
       "     0.4690169961895324,\n",
       "     0.5352011985607764,\n",
       "     0.28585910572404577,\n",
       "     1.045684307820422,\n",
       "     10.959305553807575]},\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   {'dimensions': [2], 'indices': [[0]], 'values': [1.0]},\n",
       "   {'dimensions': [1], 'indices': [[0]], 'values': [1.0]},\n",
       "   {'dimensions': [6], 'indices': [[1]], 'values': [1.0]},\n",
       "   {'dimensions': [1], 'indices': [[0]], 'values': [1.0]},\n",
       "   {'dimensions': [9], 'indices': [[0]], 'values': [1.0]},\n",
       "   {'dimensions': [2], 'values': [7.561078645344283, -7.561078645344283]},\n",
       "   {'dimensions': [2], 'values': [0.9994799568784323, 0.0005200431215677387]},\n",
       "   0.0]],\n",
       " 'schema': {'fields': [{'name': 'id', 'type': 'string'},\n",
       "   {'name': 'city', 'type': 'string'},\n",
       "   {'name': 'state', 'type': 'string'},\n",
       "   {'name': 'space', 'type': 'string'},\n",
       "   {'name': 'price', 'type': 'double'},\n",
       "   {'name': 'bathrooms', 'type': 'double'},\n",
       "   {'name': 'bedrooms', 'type': 'double'},\n",
       "   {'name': 'room_type', 'type': 'string'},\n",
       "   {'name': 'host_is_superhost', 'type': 'double'},\n",
       "   {'name': 'cancellation_policy', 'type': 'string'},\n",
       "   {'name': 'security_deposit', 'type': 'double'},\n",
       "   {'name': 'price_per_bedroom', 'type': 'double'},\n",
       "   {'name': 'number_of_reviews', 'type': 'double'},\n",
       "   {'name': 'extra_people', 'type': 'double'},\n",
       "   {'name': 'instant_bookable', 'type': 'double'},\n",
       "   {'name': 'cleaning_fee', 'type': 'double'},\n",
       "   {'name': 'review_scores_rating', 'type': 'double'},\n",
       "   {'name': 'square_feet', 'type': 'double'},\n",
       "   {'name': 'n_bathrooms_more_than_two', 'type': 'double'},\n",
       "   {'name': 'unscaled_continuous_features',\n",
       "    'type': {'base': 'double', 'type': 'tensor'}},\n",
       "   {'name': 'scaled_continuous_features',\n",
       "    'type': {'base': 'double', 'type': 'tensor'}},\n",
       "   {'name': 'room_type_index', 'type': 'double'},\n",
       "   {'name': 'host_is_superhost_index', 'type': 'double'},\n",
       "   {'name': 'cancellation_policy_index', 'type': 'double'},\n",
       "   {'name': 'instant_bookable_index', 'type': 'double'},\n",
       "   {'name': 'state_index', 'type': 'double'},\n",
       "   {'name': 'oh_encoder_room_type_index',\n",
       "    'type': {'base': 'double', 'type': 'tensor'}},\n",
       "   {'name': 'oh_encoder_host_is_superhost_index',\n",
       "    'type': {'base': 'double', 'type': 'tensor'}},\n",
       "   {'name': 'oh_encoder_cancellation_policy_index',\n",
       "    'type': {'base': 'double', 'type': 'tensor'}},\n",
       "   {'name': 'oh_encoder_instant_bookable_index',\n",
       "    'type': {'base': 'double', 'type': 'tensor'}},\n",
       "   {'name': 'oh_encoder_state_index',\n",
       "    'type': {'base': 'double', 'type': 'tensor'}},\n",
       "   {'name': 'rawPrediction', 'type': {'base': 'double', 'type': 'tensor'}},\n",
       "   {'name': 'probability', 'type': {'base': 'double', 'type': 'tensor'}},\n",
       "   {'name': 'n_bathrooms_more_than_two_prediction', 'type': 'double'}]}}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pyspark.ml.pipeline.PipelineModel, pyspark.sql.dataframe.DataFrame)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model), type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"error\":\"ModelAlreadyExistsException\",\"reason\":\"Model 'examplemodel' already exists in repository.\"}\n"
     ]
    }
   ],
   "source": [
    "%savePipeline   --pipelineName examplemodel \\\n",
    "                --pipelineModelObject model \\\n",
    "                --dataframe df \\\n",
    "                --description \"Example model to show how to upload and deploy a model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while deploying 'examplemodel' model from repository.  Response from server:\n",
      " {\"error\":\"MarathonException\",\"reason\":\"Error in Marathon. Code: 409  Body: {\\\"message\\\":\\\"An app with id [/intelligence/microservice/microservice-mleap-examplemodel] already exists.\\\"}\"}\n"
     ]
    }
   ],
   "source": [
    "%deployPipeline --pipelineName examplemodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructField(id,StringType,true),\n",
       " StructField(city,StringType,true),\n",
       " StructField(state,StringType,true),\n",
       " StructField(space,StringType,true),\n",
       " StructField(price,DoubleType,true),\n",
       " StructField(bathrooms,DoubleType,true),\n",
       " StructField(bedrooms,DoubleType,true),\n",
       " StructField(room_type,StringType,true),\n",
       " StructField(host_is_superhost,DoubleType,true),\n",
       " StructField(cancellation_policy,StringType,true),\n",
       " StructField(security_deposit,DoubleType,true),\n",
       " StructField(price_per_bedroom,DoubleType,true),\n",
       " StructField(number_of_reviews,DecimalType(11,1),true),\n",
       " StructField(extra_people,DoubleType,true),\n",
       " StructField(instant_bookable,DoubleType,true),\n",
       " StructField(cleaning_fee,DoubleType,true),\n",
       " StructField(review_scores_rating,DoubleType,true),\n",
       " StructField(square_feet,DoubleType,true),\n",
       " StructField(n_bathrooms_more_than_two,DecimalType(2,1),true)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {'fields': [\n",
    "    {'name': 'id', 'type': 'string'},\n",
    "    {'name': 'city', 'type': 'string'},\n",
    "    {'name': 'state', 'type': 'string'},\n",
    "    {'name': 'space', 'type': 'string'},\n",
    "    {'name': 'price', 'type': 'double'},\n",
    "    {'name': 'bathrooms', 'type': 'double'},\n",
    "    {'name': 'bedrooms', 'type': 'double'},\n",
    "    {'name': 'room_type', 'type': 'string'},\n",
    "    {'name': 'host_is_superhost', 'type': 'double'},\n",
    "    {'name': 'cancellation_policy', 'type': 'string'},\n",
    "    {'name': 'security_deposit', 'type': 'double'},\n",
    "    {'name': 'price_per_bedroom', 'type': 'double'},\n",
    "    {'name': 'number_of_reviews', 'type': 'double'},\n",
    "    {'name': 'extra_people', 'type': 'double'},\n",
    "    {'name': 'instant_bookable', 'type': 'double'},\n",
    "    {'name': 'cleaning_fee', 'type': 'double'},\n",
    "    {'name': 'review_scores_rating', 'type': 'double'},\n",
    "    {'name': 'square_feet', 'type': 'double'},\n",
    "    {'name': 'n_bathrooms_more_than_two', 'type': 'double'}\n",
    "]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_to_predict = [\n",
    "    '1949687',\n",
    "    ' London',\n",
    "    'Other',\n",
    "    'A unique Victorian development of special architectural and historic interest as it combines housing and workshops. This is a thriving artist community, friendly and close to the centre of the city.',\n",
    "    80.0,\n",
    "    1.0,\n",
    "    1.0,\n",
    "    'Entire home/apt',\n",
    "    0.0,\n",
    "    'moderate',\n",
    "    100.0,\n",
    "    80.0,\n",
    "    8.0,\n",
    "    10.0,\n",
    "    0.0,\n",
    "    20.0,\n",
    "    94.0,\n",
    "    380.0,\n",
    "    0.0\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_body = {'schema': schema, 'rows': [example_to_predict]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://microservice-mleap-examplemodel.microservice.intelligence.marathon.mesos:8080/examplemodel/transform'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "response = requests.post(url, json=request_body, verify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rows': [['1949687',\n",
       "   ' London',\n",
       "   'Other',\n",
       "   'A unique Victorian development of special architectural and historic interest as it combines housing and workshops. This is a thriving artist community, friendly and close to the centre of the city.',\n",
       "   80.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   'Entire home/apt',\n",
       "   0.0,\n",
       "   'moderate',\n",
       "   100.0,\n",
       "   80.0,\n",
       "   8.0,\n",
       "   10.0,\n",
       "   0.0,\n",
       "   20.0,\n",
       "   94.0,\n",
       "   380.0,\n",
       "   0.0,\n",
       "   {'dimensions': [8],\n",
       "    'values': [1.0, 1.0, 100.0, 20.0, 10.0, 8.0, 380.0, 94.0]},\n",
       "   {'dimensions': [8],\n",
       "    'values': [2.0701404784672404,\n",
       "     1.18111353148471,\n",
       "     0.4089700538272752,\n",
       "     0.4690169961895324,\n",
       "     0.5352011985607764,\n",
       "     0.28585910572404577,\n",
       "     1.045684307820422,\n",
       "     10.959305553807575]},\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   {'dimensions': [2], 'indices': [[0]], 'values': [1.0]},\n",
       "   {'dimensions': [1], 'indices': [[0]], 'values': [1.0]},\n",
       "   {'dimensions': [6], 'indices': [[1]], 'values': [1.0]},\n",
       "   {'dimensions': [1], 'indices': [[0]], 'values': [1.0]},\n",
       "   {'dimensions': [9], 'indices': [[0]], 'values': [1.0]},\n",
       "   {'dimensions': [2], 'values': [7.561078645344283, -7.561078645344283]},\n",
       "   {'dimensions': [2], 'values': [0.9994799568784323, 0.0005200431215677387]},\n",
       "   0.0]],\n",
       " 'schema': {'fields': [{'name': 'id', 'type': 'string'},\n",
       "   {'name': 'city', 'type': 'string'},\n",
       "   {'name': 'state', 'type': 'string'},\n",
       "   {'name': 'space', 'type': 'string'},\n",
       "   {'name': 'price', 'type': 'double'},\n",
       "   {'name': 'bathrooms', 'type': 'double'},\n",
       "   {'name': 'bedrooms', 'type': 'double'},\n",
       "   {'name': 'room_type', 'type': 'string'},\n",
       "   {'name': 'host_is_superhost', 'type': 'double'},\n",
       "   {'name': 'cancellation_policy', 'type': 'string'},\n",
       "   {'name': 'security_deposit', 'type': 'double'},\n",
       "   {'name': 'price_per_bedroom', 'type': 'double'},\n",
       "   {'name': 'number_of_reviews', 'type': 'double'},\n",
       "   {'name': 'extra_people', 'type': 'double'},\n",
       "   {'name': 'instant_bookable', 'type': 'double'},\n",
       "   {'name': 'cleaning_fee', 'type': 'double'},\n",
       "   {'name': 'review_scores_rating', 'type': 'double'},\n",
       "   {'name': 'square_feet', 'type': 'double'},\n",
       "   {'name': 'n_bathrooms_more_than_two', 'type': 'double'},\n",
       "   {'name': 'unscaled_continuous_features',\n",
       "    'type': {'base': 'double', 'type': 'tensor'}},\n",
       "   {'name': 'scaled_continuous_features',\n",
       "    'type': {'base': 'double', 'type': 'tensor'}},\n",
       "   {'name': 'room_type_index', 'type': 'double'},\n",
       "   {'name': 'host_is_superhost_index', 'type': 'double'},\n",
       "   {'name': 'cancellation_policy_index', 'type': 'double'},\n",
       "   {'name': 'instant_bookable_index', 'type': 'double'},\n",
       "   {'name': 'state_index', 'type': 'double'},\n",
       "   {'name': 'oh_encoder_room_type_index',\n",
       "    'type': {'base': 'double', 'type': 'tensor'}},\n",
       "   {'name': 'oh_encoder_host_is_superhost_index',\n",
       "    'type': {'base': 'double', 'type': 'tensor'}},\n",
       "   {'name': 'oh_encoder_cancellation_policy_index',\n",
       "    'type': {'base': 'double', 'type': 'tensor'}},\n",
       "   {'name': 'oh_encoder_instant_bookable_index',\n",
       "    'type': {'base': 'double', 'type': 'tensor'}},\n",
       "   {'name': 'oh_encoder_state_index',\n",
       "    'type': {'base': 'double', 'type': 'tensor'}},\n",
       "   {'name': 'rawPrediction', 'type': {'base': 'double', 'type': 'tensor'}},\n",
       "   {'name': 'probability', 'type': {'base': 'double', 'type': 'tensor'}},\n",
       "   {'name': 'n_bathrooms_more_than_two_prediction', 'type': 'double'}]}}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
